{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import Adam\n",
    "from utils import *  # NeuroGraph\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function for generating multiple sets of arguments from one object ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function from one dictionary to multiple sets of params\n",
    "def grid_from_param(dic): #, append_model_name = True, model_name_default = 'default'):\n",
    "    # retrieve all lists to choose parameters from\n",
    "    names = []\n",
    "    lens = []\n",
    "    for name in dic:\n",
    "        item = dic[name]\n",
    "        if(type(item)==list):\n",
    "            names.append(name)\n",
    "            lens.append(len(item))\n",
    "\n",
    "    #helper\n",
    "    count = 1\n",
    "    mults = []\n",
    "    for l in lens:\n",
    "        mults.append(count)\n",
    "        count *= l\n",
    "    #print(mults)\n",
    "    #print(count)\n",
    "    #print(lens)\n",
    "\n",
    "    #construct the grid\n",
    "    params = []\n",
    "    n = len(lens)\n",
    "    for i in range(count):\n",
    "        param = dic.copy()\n",
    "        param['tune_name'] = '_'\n",
    "        for j in range(n):\n",
    "            param[names[j]] = dic[names[j]][i//mults[j] % lens[j]]\n",
    "            param['tune_name'] += f\"{names[j]}{param[names[j]]}_\"\n",
    "        params.append(param)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "argsDictTune = {\n",
    "    # choose dataset form: ADNI(BOLD), HCP(CORR), BOLD+CORR\n",
    "    'dataset' : \"ADNI\",\n",
    "    # data path\n",
    "    'dataset_dir' : \"../../data/ADNI/\", # ========================================= locally changed? =========================================\n",
    "    # choose from: GCNConv, GINConv, SGConv, GeneralConv, GATConv\n",
    "    #'edge_dir_prefix' : \"pearsonpearson_/pearsonpearson_\",\n",
    "    'edge_dir_prefix' : \"cosinecosine_/cosinecosine_\",\n",
    "    #'edge_dir_prefix' : \"pairwise_PC_aHOFC/aHOFC\",\n",
    "    'model' : \"GCNConv\" ,\n",
    "    'num_classes' : 2,  # ADNI - binary classification\n",
    "    'weight_decay' : 0.0005,\n",
    "    'batch_size' : 16,\n",
    "    'hidden_mlp' : 64,\n",
    "    'hidden' : 32,\n",
    "    'num_layers' : 3,\n",
    "    'runs' : 1,\n",
    "    'lr' : [1e-3, 5e-4, 2e-4, 1e-4, 5e-5, 1e-5],\n",
    "    #'lr' : [1e-3],\n",
    "    'epochs' : 200,\n",
    "    'seed' : 42,\n",
    "}\n",
    "\n",
    "class Args: # now it's just a wrapper for compatibility. Everything now packed up in the dictionary.\n",
    "    def __init__(self, param_dict) -> None:\n",
    "        # wrapped. see argDict above.\n",
    "        self.dataset = param_dict['dataset']\n",
    "        self.dataset_dir = param_dict['dataset_dir']\n",
    "        self.edge_dir_prefix = param_dict['edge_dir_prefix']\n",
    "        self.model = param_dict['model']\n",
    "        self.num_classes = param_dict['num_classes']\n",
    "        self.weight_decay = param_dict['weight_decay']\n",
    "        self.batch_size = param_dict['batch_size']\n",
    "        self.hidden_mlp = param_dict['hidden_mlp']\n",
    "        self.hidden = param_dict['hidden']\n",
    "        self.num_layers = param_dict['num_layers']\n",
    "        self.runs = param_dict['runs']\n",
    "        self.lr = param_dict['lr']\n",
    "        self.epochs = param_dict['epochs']\n",
    "        self.seed = param_dict['seed']\n",
    "        self.device = \"cuda\" if self.model != \"GATConv\" else \"cpu\"\n",
    "        self.tune_name = param_dict['tune_name'] if \"tune_name\" in param_dict else None\n",
    "    def tuning_list(param_dicts : dict):\n",
    "        p = grid_from_param(param_dicts)\n",
    "        return [Args(x) for x in p]\n",
    "\n",
    "\n",
    "#print([x['lr'] for x in grid_from_param(argsdict)])\n",
    "args_list = Args.tuning_list(argsDictTune)\n",
    "fix_seed(args_list[0].seed)\n",
    "\n",
    "#print(len(Args.tuning_list(argsDictTune)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading our Datasets\n",
    "use our HCP correlation matrix dataset, train/test split file, label file.\n",
    "\n",
    "HCP data is downloaded from https://drive.google.com/drive/folders/166wCCtPOEL0O25FxzwB0I8AQA8b6Q9U1?usp=drive_link \n",
    "\n",
    "other files are in the data folder\n",
    "\n",
    "use our ADNI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_adni_data(args):\n",
    "    fMRI_path = args.dataset_dir + \"fmri_signal.mat\"\n",
    "    ICV_path = args.dataset_dir + \"ICV.mat\"\n",
    "    AGE_path = args.dataset_dir + \"AGE.mat\"\n",
    "    DX_path = args.dataset_dir + \"DX.mat\"\n",
    "    gender_path = args.dataset_dir + \"gender.mat\"\n",
    "    fMRI_data_path = args.dataset_dir + \"fMRIdata_ADNI2_ADNI3.csv\"\n",
    "    # participants_path = r'./data/ADNI/participants.tsv'\n",
    "\n",
    "    # read fMRI_path\n",
    "    fmri_data = scipy.io.loadmat(fMRI_path)['fmri_signal']\n",
    "    fMRI_data = [fmri_data[i][0] for i in range(len(fmri_data))]\n",
    "\n",
    "    # read ICV_path\n",
    "    icv_data = scipy.io.loadmat(ICV_path)['ICV']\n",
    "    ICV_data = pd.DataFrame([icv_data[i][0] for i in range(len(icv_data))])\n",
    "\n",
    "    # read AGE_path\n",
    "    age_data = scipy.io.loadmat(AGE_path)['AGE']\n",
    "    AGE_data = pd.DataFrame([age_data[i][0] for i in range(len(age_data))])\n",
    "\n",
    "    # read gender_path\n",
    "    gender_data = scipy.io.loadmat(gender_path)['gender']\n",
    "    gender_data = pd.DataFrame([gender_data[i][0] for i in range(len(gender_data))])\n",
    "\n",
    "    # read DX_path\n",
    "    dx_data = scipy.io.loadmat(DX_path)['DX']\n",
    "    DX_data = pd.DataFrame([dx_data[i][0] for i in range(len(dx_data))])\n",
    "\n",
    "    # for all above variable, add a df.insert(0, 'Image_ID', range(1, 1 + len(fMRI_data))) to add Image_ID column\n",
    "    for df in [ICV_data, AGE_data, gender_data, DX_data]:\n",
    "        df.insert(0, 'Image_ID', range(1, 1 + len(fMRI_data)))\n",
    "\n",
    "    # give their column names, EstimatedTotalIntraCranialVol, Age, Gender, Diagnosis\n",
    "    ICV_data.columns = ['Image_ID', 'EstimatedTotalIntraCranialVol']\n",
    "    AGE_data.columns = ['Image_ID', 'Age']\n",
    "    gender_data.columns = ['Image_ID', 'Gender']\n",
    "    DX_data.columns = ['Image_ID', 'Diagnosis']\n",
    "    Image_ID = ICV_data['Image_ID']\n",
    "\n",
    "    data_dict = {\n",
    "        'fMRI_data': fMRI_data,\n",
    "        'ICV_data': ICV_data,\n",
    "        'AGE_data': AGE_data,\n",
    "        'gender_data': gender_data,\n",
    "        'DX_data': DX_data\n",
    "    }\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_args(args:Args):\n",
    "\n",
    "    # Label path\n",
    "    labels_file = args.dataset_dir + 'y.csv'\n",
    "    # Load labels\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "\n",
    "    # for ADNI Dataset\n",
    "    if args.dataset == \"ADNI\":\n",
    "        adni_data = read_adni_data(args)\n",
    "        fMRI_data = adni_data['fMRI_data']\n",
    "        ICV_data = adni_data['ICV_data']\n",
    "        AGE_data = adni_data['AGE_data']\n",
    "        gender_data = adni_data['gender_data']\n",
    "        DX_data = adni_data['DX_data']\n",
    "\n",
    "        # only keep healthy control and AD. namely 2 and 0\n",
    "        labels_df = labels_df[labels_df['Diagnosis'].isin([2, 0])].reset_index(drop=True)\n",
    "        # change all 2 to 1\n",
    "        labels_df['Diagnosis'] = labels_df['Diagnosis'].replace({2: 1})\n",
    "\n",
    "        dataset = []\n",
    "        # traverse the labels_df by i\n",
    "        for i in range(len(labels_df)):\n",
    "            # print('i:', i)\n",
    "            #print(i)\n",
    "            IID = labels_df['IID'][i]\n",
    "            y = labels_df['Diagnosis'][i]\n",
    "            # turn y to <class 'torch.Tensor'>\n",
    "            y = torch.tensor(y, dtype=torch.long)\n",
    "            # z-score normalization for each column of each subject\n",
    "            subject_data = fMRI_data[IID]\n",
    "            # fill 0 with 1\n",
    "            subject_data[subject_data == 0] = 1\n",
    "            subject_data = (subject_data - np.mean(subject_data, axis=0)) / np.std(subject_data, axis=0)\n",
    "            # x = torch.tensor(subject_data[:100, :], dtype=torch.float)\n",
    "            #print(f\"hello: {i}\")\n",
    "\n",
    "            try:\n",
    "                edge_attr = pd.read_csv(args.dataset_dir + 'fmri_edge/' + args.edge_dir_prefix + str(IID) + '.csv')# ========================================= locally changed? =========================================\n",
    "            except:\n",
    "                print('File \\\"' + args.dataset_dir + 'fmri_edge/' + args.edge_dir_prefix + str(IID) + '.csv\\\" not found. Skipping.')\n",
    "                continue\n",
    "            x = torch.tensor(edge_attr.to_numpy(), dtype=torch.float)\n",
    "            np.fill_diagonal(edge_attr.to_numpy(), 0)\n",
    "            #print(f\"read: {i}\")\n",
    "\n",
    "            # 获取10%最大的元素的阈值\n",
    "            threshold = np.percentile(edge_attr, 90)\n",
    "            \n",
    "            # 只保留大于阈值的元素，其他置为0\n",
    "            edge_attr[edge_attr < threshold] = 0\n",
    "\n",
    "            edge_index = np.vstack(np.nonzero(edge_attr.to_numpy()))\n",
    "\n",
    "            # only keep edge_attr with edge_index's value\n",
    "            # 只保留与非零 edge_index 对应的 edge_attr\n",
    "            filtered_edge_attr = edge_attr.to_numpy()[edge_index[0], edge_index[1]]\n",
    "\n",
    "            # 确保 edge_attr 是一维张量\n",
    "            filtered_edge_attr = torch.tensor(filtered_edge_attr, dtype=torch.float)\n",
    "            #print(f\"data creating: {i}\")\n",
    "\n",
    "            data = Data(x=x, edge_index=torch.tensor(edge_index, dtype=torch.long), edge_attr=filtered_edge_attr, y=y)\n",
    "            #print(f\"appending: {i}\")\n",
    "\n",
    "\n",
    "            # choose from the special case\n",
    "            if data.edge_index[0].shape[0] != 1000:\n",
    "                #print(f\"skipping: {i}\")\n",
    "                continue\n",
    "\n",
    "            dataset.append(data)\n",
    "\n",
    "        # get train and test data\n",
    "        train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "        return train_data, test_data\n",
    "        \n",
    "    # for HCP \n",
    "    elif args.dataset == \"HCP\":\n",
    "        # train_ids = pd.read_csv(args.dataset_dir + 'ids_train.csv')['IID'].values\n",
    "        # test_ids = pd.read_csv(args.dataset_dir + 'ids_test.csv')['IID'].values\n",
    "        \n",
    "        # train_data = [data for data in (load_mat_data(iid) for iid in train_ids) if data is not None]\n",
    "        # test_data = [data for data in (load_mat_data(iid) for iid in test_ids) if data is not None]\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Functions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, args: Args, train_loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:  \n",
    "        data = data.to(args.device)\n",
    "        out = model(data) \n",
    "        loss = criterion(out, data.y) \n",
    "        total_loss +=loss\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        optimizer.zero_grad()\n",
    "    return total_loss/len(train_loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, args: Args, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(args.device)\n",
    "            out = model(data)\n",
    "            probs = F.softmax(out, dim=1)  # Calculate probabilities\n",
    "            preds = out.argmax(dim=1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy()[:, 1])  # Keep the probabilities of the positive class\n",
    "            all_labels.append(data.y.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_probs = np.concatenate(all_probs)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    auroc = roc_auc_score(all_labels, all_probs)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'auroc': auroc,\n",
    "        'sensitivity': sensitivity,\n",
    "        'specificity': specificity,\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# test for multiclass\n",
    "def test_multiclass(model, args: Args, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(args.device)\n",
    "            out = model(data)\n",
    "            probs = F.softmax(out, dim=1)  # 计算所有类的概率\n",
    "            preds = out.argmax(dim=1)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            all_labels.append(data.y.cpu().numpy())\n",
    "    \n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    # 计算指标\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    # 如果你需要计算AUROC，对于多分类问题，可以使用平均方法\n",
    "    auroc = roc_auc_score(all_labels, all_probs, multi_class='ovr')  # 'ovr'表示一对多（one-vs-rest）策略\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')  # 使用加权平均\n",
    "    # confusion_matrix 需要转换为多分类版本\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # sensitivity 和 specificity 的计算需要根据每个类分别计算\n",
    "    sensitivities = []\n",
    "    specificities = []\n",
    "    for i in range(cm.shape[0]):\n",
    "        tp = cm[i, i]\n",
    "        fn = cm[i, :].sum() - tp\n",
    "        fp = cm[:, i].sum() - tp\n",
    "        tn = cm.sum() - (tp + fn + fp)\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy,\n",
    "        'auroc': auroc,\n",
    "        'sensitivity': np.mean(sensitivities),\n",
    "        'specificity': np.mean(specificities),\n",
    "        'f1_score': f1\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def bench_from_args(args: Args, verbose = False):\n",
    "    # get train and test data\n",
    "    # train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "    train_data, test_data = load_data_from_args(args)\n",
    "    train_data, val_data = train_test_split(train_data, test_size=0.125, random_state=123)\n",
    "\n",
    "    # create data loaders\n",
    "    train_loader = DataLoader(train_data, args.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, args.batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, args.batch_size, shuffle=False)\n",
    "\n",
    "    checkpoints_dir = './checkpoints/'\n",
    "    if not os.path.exists(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)\n",
    "\n",
    "    val_acc_history, test_acc_history, test_loss_history = [],[],[]\n",
    "    #seed = 42\n",
    "    for index in range(args.runs):\n",
    "        gnn = eval(args.model)\n",
    "        model = ResidualGNNs(args, train_data, args.hidden, args.hidden_mlp, args.num_layers, gnn).to(args.device) ## apply GNN*\n",
    "        if (verbose):\n",
    "            print(model)\n",
    "        #total_params = sum(p.numel() for p in model.parameters())\n",
    "        loss, test_acc = [], []\n",
    "        best_val_auroc, best_val_loss = 0.0,0.0\n",
    "        for epoch in range(args.epochs):\n",
    "            loss = train(model, args, train_loader)\n",
    "            train_metrics = test(model, args, train_loader)\n",
    "            val_metrics = test(model, args, val_loader)\n",
    "            # test_metrics = test(model, args, test_loader)\n",
    "            if (verbose):\n",
    "                print(\"epoch: {}, loss: {}, \\ntrain_metrics:{}, \\nval_metrics:{}, \\ntest_metrics:{}\".format(epoch, np.round(loss.item(),6), train_metrics, val_metrics, test_metrics))\n",
    "            \n",
    "            \n",
    "            if val_metrics['auroc'] > best_val_auroc:\n",
    "                best_val_auroc = val_metrics['auroc']\n",
    "                torch.save(model.state_dict(), f\"{checkpoints_dir}{args.dataset}_{args.edge_dir_prefix.split('/')[0]}_{args.model}{args.tune_name}task-checkpoint-best-auroc.pkl\")\n",
    "\n",
    "        #test the model\n",
    "        model.load_state_dict(torch.load(f\"{checkpoints_dir}{args.dataset}_{args.edge_dir_prefix.split('/')[0]}_{args.model}{args.tune_name}task-checkpoint-best-auroc.pkl\"))\n",
    "        model.eval()\n",
    "        # test_acc = test(model, args, test_loader)['accuracy']\n",
    "        test_metrics = test(model, args, test_loader)\n",
    "        # test_acc = test_metrics['accuracy']\n",
    "        # test_loss = train(model, args, test_loader).item()\n",
    "        # test_acc_history.append(test_acc)\n",
    "        # test_loss_history.append(test_loss)\n",
    "        if (verbose):\n",
    "            print('test_metrics:', test_metrics)\n",
    "        return test_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test_metric_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m args \u001b[38;5;129;01min\u001b[39;00m args_list:\n\u001b[1;32m----> 3\u001b[0m     met \u001b[38;5;241m=\u001b[39m bench_from_args(args, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m     test_metric_list\u001b[38;5;241m.\u001b[39mappend(met)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(args\u001b[38;5;241m.\u001b[39mtune_name)\n",
      "Cell \u001b[1;32mIn[6], line 132\u001b[0m, in \u001b[0;36mbench_from_args\u001b[1;34m(args, verbose)\u001b[0m\n\u001b[0;32m    130\u001b[0m best_val_auroc, best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(args\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m--> 132\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train(model, args, train_loader)\n\u001b[0;32m    133\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m test(model, args, train_loader)\n\u001b[0;32m    134\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m test(model, args, val_loader)\n",
      "Cell \u001b[1;32mIn[6], line 6\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, args, train_loader)\u001b[0m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      5\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_loader:  \n\u001b[0;32m      7\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m     out \u001b[38;5;241m=\u001b[39m model(data) \n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\loader\\dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Batch\u001b[38;5;241m.\u001b[39mfrom_data_list(\n\u001b[0;32m     28\u001b[0m         batch,\n\u001b[0;32m     29\u001b[0m         follow_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_batch,\n\u001b[0;32m     30\u001b[0m         exclude_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude_keys,\n\u001b[0;32m     31\u001b[0m     )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\data\\batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[1;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m collate(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m     99\u001b[0m         data_list\u001b[38;5;241m=\u001b[39mdata_list,\n\u001b[0;32m    100\u001b[0m         increment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    101\u001b[0m         add_batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_list[\u001b[38;5;241m0\u001b[39m], Batch),\n\u001b[0;32m    102\u001b[0m         follow_batch\u001b[38;5;241m=\u001b[39mfollow_batch,\n\u001b[0;32m    103\u001b[0m         exclude_keys\u001b[38;5;241m=\u001b[39mexclude_keys,\n\u001b[0;32m    104\u001b[0m     )\n\u001b[0;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\data\\collate.py:143\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (add_batch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stores[\u001b[38;5;241m0\u001b[39m], NodeStorage)\n\u001b[0;32m    141\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m stores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcan_infer_num_nodes):\n\u001b[0;32m    142\u001b[0m         repeats \u001b[38;5;241m=\u001b[39m [store\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores]\n\u001b[1;32m--> 143\u001b[0m         out_store\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m repeat_interleave(repeats, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    144\u001b[0m         out_store\u001b[38;5;241m.\u001b[39mptr \u001b[38;5;241m=\u001b[39m cumsum(torch\u001b[38;5;241m.\u001b[39mtensor(repeats, device\u001b[38;5;241m=\u001b[39mdevice))\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, slice_dict, inc_dict\n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\data\\collate.py:315\u001b[0m, in \u001b[0;36mrepeat_interleave\u001b[1;34m(repeats, device)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat_interleave\u001b[39m(\n\u001b[0;32m    312\u001b[0m     repeats: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    313\u001b[0m     device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 315\u001b[0m     outs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfull((n, ), i, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(repeats)]\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\28548\\.conda\\envs\\pytorch\\Lib\\site-packages\\torch_geometric\\data\\collate.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrepeat_interleave\u001b[39m(\n\u001b[0;32m    312\u001b[0m     repeats: List[\u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    313\u001b[0m     device: Optional[torch\u001b[38;5;241m.\u001b[39mdevice] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 315\u001b[0m     outs \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfull((n, ), i, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m i, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(repeats)]\n\u001b[0;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_metric_list = []\n",
    "for args in args_list:\n",
    "    met = bench_from_args(args, verbose=False)\n",
    "    test_metric_list.append(met)\n",
    "    print(args.tune_name)\n",
    "    print(met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demo of full usage ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_lr0.001_\n",
      "{'accuracy': 0.896551724137931, 'auroc': 0.9066413662239089, 'sensitivity': 0.9529411764705882, 'specificity': 0.7419354838709677, 'f1_score': 0.9310344827586207}\n",
      "_lr0.0005_\n",
      "{'accuracy': 0.8793103448275862, 'auroc': 0.9423149905123339, 'sensitivity': 0.9529411764705882, 'specificity': 0.6774193548387096, 'f1_score': 0.9204545454545454}\n",
      "_lr0.0002_\n",
      "{'accuracy': 0.8706896551724138, 'auroc': 0.9316888045540797, 'sensitivity': 0.9411764705882353, 'specificity': 0.6774193548387096, 'f1_score': 0.9142857142857143}\n",
      "_lr0.0001_\n",
      "{'accuracy': 0.7931034482758621, 'auroc': 0.8846299810246678, 'sensitivity': 0.788235294117647, 'specificity': 0.8064516129032258, 'f1_score': 0.8481012658227848}\n",
      "_lr5e-05_\n",
      "{'accuracy': 0.8879310344827587, 'auroc': 0.9233396584440228, 'sensitivity': 0.9529411764705882, 'specificity': 0.7096774193548387, 'f1_score': 0.9257142857142857}\n",
      "_lr1e-05_\n",
      "{'accuracy': 0.8620689655172413, 'auroc': 0.9119544592030361, 'sensitivity': 0.9529411764705882, 'specificity': 0.6129032258064516, 'f1_score': 0.9101123595505618}\n"
     ]
    }
   ],
   "source": [
    "argsDictTune_p = {\n",
    "    # choose dataset form: ADNI(BOLD), HCP(CORR), BOLD+CORR\n",
    "    'dataset' : \"ADNI\",\n",
    "    # data path\n",
    "    'dataset_dir' : \"../../data/ADNI/\", # ========================================= locally changed? =========================================\n",
    "    # choose from: GCNConv, GINConv, SGConv, GeneralConv, GATConv\n",
    "    'edge_dir_prefix' : \"pearsonpearson_/pearsonpearson_\",\n",
    "    #'edge_dir_prefix' : \"cosinecosine_/cosinecosine_\",\n",
    "    #'edge_dir_prefix' : \"pairwise_PC_aHOFC/aHOFC\",\n",
    "    'model' : \"GCNConv\" ,\n",
    "    'num_classes' : 2,  # ADNI - binary classification\n",
    "    'weight_decay' : 0.0005,\n",
    "    'batch_size' : 16,\n",
    "    'hidden_mlp' : 64,\n",
    "    'hidden' : 32,\n",
    "    'num_layers' : 3,\n",
    "    'runs' : 1,\n",
    "    'lr' : [1e-3, 5e-4, 2e-4, 1e-4, 5e-5, 1e-5],\n",
    "    #'lr' : [1e-3],\n",
    "    'epochs' : 200,\n",
    "    'seed' : 42,\n",
    "}\n",
    "#print([x['lr'] for x in grid_from_param(argsdict)])\n",
    "args_list_p = Args.tuning_list(argsDictTune_p)\n",
    "fix_seed(args_list_p[0].seed)\n",
    "test_metric_list_p = []\n",
    "for args in args_list_p:\n",
    "    met = bench_from_args(args, verbose=False)\n",
    "    test_metric_list_p.append(met)\n",
    "    print(args.tune_name)\n",
    "    print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_lr0.001_\n",
      "{'accuracy': 0.7327586206896551, 'auroc': 0.5635673624288425, 'sensitivity': 1.0, 'specificity': 0.0, 'f1_score': 0.845771144278607}\n",
      "_lr0.0005_\n",
      "{'accuracy': 0.7241379310344828, 'auroc': 0.5889943074003795, 'sensitivity': 0.9411764705882353, 'specificity': 0.12903225806451613, 'f1_score': 0.8333333333333334}\n",
      "_lr0.0002_\n",
      "{'accuracy': 0.6810344827586207, 'auroc': 0.5984819734345351, 'sensitivity': 0.8823529411764706, 'specificity': 0.12903225806451613, 'f1_score': 0.8021390374331551}\n",
      "_lr0.0001_\n",
      "{'accuracy': 0.3879310344827586, 'auroc': 0.5138519924098672, 'sensitivity': 0.2235294117647059, 'specificity': 0.8387096774193549, 'f1_score': 0.3486238532110092}\n",
      "_lr5e-05_\n",
      "{'accuracy': 0.4396551724137931, 'auroc': 0.5111954459203036, 'sensitivity': 0.35294117647058826, 'specificity': 0.6774193548387096, 'f1_score': 0.48}\n",
      "_lr1e-05_\n",
      "{'accuracy': 0.6206896551724138, 'auroc': 0.510056925996205, 'sensitivity': 0.7529411764705882, 'specificity': 0.25806451612903225, 'f1_score': 0.7441860465116279}\n"
     ]
    }
   ],
   "source": [
    "argsDictTune_a = {\n",
    "    # choose dataset form: ADNI(BOLD), HCP(CORR), BOLD+CORR\n",
    "    'dataset' : \"ADNI\",\n",
    "    # data path\n",
    "    'dataset_dir' : \"../../data/ADNI/\", # ========================================= locally changed? =========================================\n",
    "    # choose from: GCNConv, GINConv, SGConv, GeneralConv, GATConv\n",
    "    #'edge_dir_prefix' : \"pearsonpearson_/pearsonpearson_\",\n",
    "    #'edge_dir_prefix' : \"cosinecosine_/cosinecosine_\",\n",
    "    'edge_dir_prefix' : \"pairwise_PC_aHOFC/aHOFC\",\n",
    "    'model' : \"GCNConv\" ,\n",
    "    'num_classes' : 2,  # ADNI - binary classification\n",
    "    'weight_decay' : 0.0005,\n",
    "    'batch_size' : 16,\n",
    "    'hidden_mlp' : 64,\n",
    "    'hidden' : 32,\n",
    "    'num_layers' : 3,\n",
    "    'runs' : 1,\n",
    "    'lr' : [1e-3, 5e-4, 2e-4, 1e-4, 5e-5, 1e-5],\n",
    "    #'lr' : [1e-3],\n",
    "    'epochs' : 200,\n",
    "    'seed' : 42,\n",
    "}\n",
    "#print([x['lr'] for x in grid_from_param(argsdict)])\n",
    "args_list_a = Args.tuning_list(argsDictTune_a)\n",
    "fix_seed(args_list_a[0].seed)\n",
    "test_metric_list_a = []\n",
    "for args in args_list_a:\n",
    "    met = bench_from_args(args, verbose=False)\n",
    "    test_metric_list_a.append(met)\n",
    "    print(args.tune_name)\n",
    "    print(met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NueroGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
